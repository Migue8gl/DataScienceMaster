{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"line-height:2px;border: solid orange\">\n",
    "    <p>\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:20\"> Visión por Computador &nbsp;&nbsp;\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:16\"> Master en Ciencias de Datos e Ingeniería de Ordenadores   &nbsp;&nbsp;\n",
    "  <p style=\"color:blue;font-family:arial;text-align:right;font-size:16\"> Rosa Mª. Rodríguez Sánchez   &nbsp;&nbsp;\n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:10\"> Dpto. Ciencias de la Computación e Inteligencia Artificial. &nbsp;&nbsp;  \n",
    "    <p style=\"color:blue;font-family:arial;text-align:right;font-size:10\"> ETSIIT. Universidad de Granada   &nbsp;&nbsp;\n",
    "        <p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 5 (Parte I) Transformada de Hotelling (Transformada discreta Karhunen-Loeve o PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "La transformada Hotelling o PCA, también conocida como transformada autovector, componente principal o transformada discreta de Karhunen-Loéve, se basa en\n",
    "propiedades estadísticas de representaciones vectoriales. El objetivo es obtener una representación de las muestras con menor número de rasgos. Para ellos la transformada Hotelling lo que hace es extraer los rasgos más relevantes de un conjunto de muestras.  \n",
    "<img src=\"pca_line.png\">\n",
    "\n",
    "Considera el conjunto de puntos 2D como se muestra en el figura de arriba. Cada dimensión se corresponde con un rasgo. Como se puede ver los puntos se alinean alrededor de la línea azul. Así una forma de reducir la dimensionalidad es representar los datos con solamente la línea azul, reduciendo la dimensionalidad de 2D a 1D.\n",
    "\n",
    "Además, vemos que los puntos tiene una mayor varianza en la dirección del rasgo 1 (eje x) que en la dirección del rasgo 2 (eje y). Por lo tanto si conocemos la posición de un punto a lo largo de linea azul tenemos más información acerca del punto que si solamente conocemos el valor del punto para el rasgo 1 o para el rasgo 2. \n",
    "\n",
    "De esta forma PCA nos permitirá encontrar la dirección en la que los datos tiene la mayor varianza. De hecho si ejecutamos PCA sobre el conjunto de datos nos devuelve 2 vectores que  se denominan autovectores que son las componentes principales del conjunto de datos.\n",
    "<img src=\"pca_eigen.png\">\n",
    "\n",
    "El tamaño de cada autovector lo indica el correspondiente autovalor. El autovalor nos informa de la varianza de los datos a lo largo de la componente principal. El origen (comienzo ) de cada autovector es el centro de todos los puntos en el conjunto. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasos a seguir para aplicar PCA\n",
    "Dado un  conjunto de datos $X=\\{x_1,x_2,\\dots,x_n\\}$  donde cada $x_i=\\{x_{i1},x_{i2},\\dots,x_{ip}\\}$ tiene dimension $p$, queremos obtener un conjunto de datos $Y$ que se pueda representar cada muestra con un menor número de datos.\n",
    "Asi los pasos a seguir para obtener el conjunto de datos $Y$ son: \n",
    "<ol>\n",
    "    <li> Escribir el conjunto de datos $X$ en una matriz. Cada $x_i$ se escribe en una fila. Obteniendo una matrix $X$ de dimensión $n\\times p$\n",
    "    <li> Obtener la media de cada columna  como $m[j]=\\frac{1}{n}\\sum_{i=1}^n X[i,j]$. Siendo $m$ un vector de dimensión $p\\times 1$\n",
    "    <li> Obtener la matriz centrada $B= X-h m^T$. Siendo h un vector columna $n\\times 1$ de unos. Siendo $B$ una matriz $n\\times p$ .\n",
    "    <li> Encontrar la matriz de covarianza de B como $C=\\frac{1}{n-1}B^T B $  \n",
    "    <li> Obtener los autovectores $V$ y autovalores $D$ de $C$. $D$ es una matriz $p\\times p $ diagonal. $V$ es una metriz $p\\times p$\n",
    "    <li> Aplicar los autovectores $V$ a la matriz $B$, obteniendo $Y$\n",
    "</ol>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "Supongamos que tenemos el siguiente conjunto de imágenes \n",
    "<table border=0>\n",
    "    <tr><td><img src='TH/a.jpg'></td><td><img src='TH/b.jpg'></td><td><img src='TH/c.jpg'></td></tr>\n",
    "    <tr><td><img src='TH/d.jpg'></td><td><img src='TH/d.jpg'></td><td></td></tr>\n",
    "</table>\n",
    "Nuestro objetivo es reducir el número de imágenes para representar la misma información de la camioneta.\n",
    "Para ello veamos como se ejecuta los pasos comentados anteriormente.\n",
    "En el siguiente código se construye la matriz $X$ a partir del conjunto de imágenes de la camioneta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "#Creamos la matriz X\n",
    "\n",
    "img_a=cv2.imread('TH/a.jpg',0)\n",
    "img_b=cv2.imread('TH/b.jpg',0)\n",
    "img_c=cv2.imread('TH/c.jpg',0)\n",
    "img_d=cv2.imread('TH/d.jpg',0)\n",
    "img_e=cv2.imread('TH/e.jpg',0)\n",
    "#ravel reduce las dimensiones a 1 dejando la imagen como un vector\n",
    "#X es una matriz donde por ejemplo en la fila 0 tiene la informacion del pixel (0,0) de cada imagen\n",
    "X=np.array([np.ravel(img_a),np.ravel(img_b),np.ravel(img_c),np.ravel(img_d),np.ravel(img_e)])\n",
    "X=X.T\n",
    "X=X.astype('float32')\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que las muestras son los pixeles, y los rasgos son los valores que toman cada pixel en las 5 imágenes. A continuación obtenemos la medias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=np.mean(X, axis=0) \n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora construimos la matriz B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h= np.ones((X.shape[0],1),dtype='uint8')\n",
    "B=X-h*m\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos la covariaza de B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C=1.0/(X.shape[0]-1)*np.dot(B.T,B)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los autovalores y autovectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "D, V = LA.eig(C)\n",
    "print(\"Autovalores: \",D)\n",
    "print(\"Autovectores: \",V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D son los autovalores y V son los autovectores por columna. Aplicamos la transformación a continuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "y=np.dot(B,V)\n",
    "h,w=img_a.shape\n",
    "img_at=np.reshape(y[:,0],(h,w))\n",
    "img_bt=np.reshape(y[:,1],(h,w))\n",
    "img_ct=np.reshape(y[:,2],(h,w))\n",
    "img_dt=np.reshape(y[:,3],(h,w))\n",
    "img_et=np.reshape(y[:,4],(h,w))\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(2,3,1),plt.imshow(img_at,'gray')\n",
    "plt.subplot(2,3,2),plt.imshow(img_bt,'gray')\n",
    "plt.subplot(2,3,3),plt.imshow(img_ct,'gray')\n",
    "plt.subplot(2,3,4),plt.imshow(img_dt,'gray')\n",
    "plt.subplot(2,3,5),plt.imshow(img_et,'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando un subconjunto de autovectores\n",
    "La reconstrucción de la matriz $X$ se puede obtener como:\n",
    "$X_{r}=V Y+h m^T$\n",
    "Siendo h un vector columna $n\\times 1$ de unos.\n",
    "\n",
    "Supongamos que solamente  usamos un subconjunto de autovectores de $V$ formando una matriz $V_K$ que se obtiene  a partir de los K autovectores de V asociados a los  K autovalores de\n",
    "mayor valor, para obtener una matriz de Kxp dimensiones. Los vectores $Y_K$ sería la submatriz de $Y$ que considera las $K\\times n$ dimensionales de $Y$. Ahora la reconstruccion sería:\n",
    "$\\overline{X}=V_K Y_K+h m^T$. \n",
    "\n",
    "Se puede demostrar que el error al cuadrado medio entre $X$ y $\\overline{X}$ viene dado por \n",
    "$e_K =\\sum_{j=1}^p\\lambda_j -\\sum_{j=1}^K\\lambda_j =\\sum_{j=K+1}^p\\lambda_j $\n",
    "\n",
    "Ya que los autovalores  $\\lambda_i$  decrecen monótonamente, también muestra que el error puede\n",
    "minimizarse seleccionando los K autovectores asociados con los autovalores de mayor\n",
    "valor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "En este ejercicio se pide al estudiante que aplique la transformada a un conjunto de imágenes satélite de la ciudad de Adra. Establecer el error cometido cuando se usa:\n",
    "\n",
    "    Solamente la primera imagen correspondiente al primer autovalor\n",
    "    Solamente las dos primeras imágenes correspondientes al primer y segundo autovalor\n",
    "    ...\n",
    "    Todos las imágenes.\n",
    "\n",
    "Mostrar una gráfica que muestre el error cometido cuando se usan las diferentes imágenes obtenidas. Es importante desarrollar un conjunto de conclusiones sobre los datos obtenidos.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
