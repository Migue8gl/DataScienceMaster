{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Support Vector Machines (SVMs) y optimización de parámetros\"\n",
        "theme: Montpellier\n",
        "author: \"Máster en Ciencias de Datos e Ingeniería de Computadores, Minería de Datos - Preprocesamiento y clasificación\"\n",
        "date: 11/11/2024\n",
        "date-format: long\n",
        "toc: true\n",
        "toc-title: Tabla de Contenidos\n",
        "toc-depth: 1\n",
        "execute:\n",
        "  echo: true\n",
        "output:\n",
        "  beamer_presentation:\n",
        "    slide_level: 1\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "    code-summary: \"Muestra código\"\n",
        "    fig-width: 5\n",
        "    fig-height: 3\n",
        "    fig-align: left\n",
        "  beamer:\n",
        "    fig-width: 4\n",
        "    fig-height: 2\n",
        "  revealjs:\n",
        "    theme: dark\n",
        "    fig-align: left\n",
        "    fig-height: 5\n",
        "    fig-cap-location: margin\n",
        "    smaller: true\n",
        "---\n",
        "\n",
        "## Support Vector Machines (SVMs)\n",
        "\n",
        "En esta sesión vamos a repasar los principales métodos de SVMs vistos en teoría. \n",
        "\n",
        "Se aplica una evaluación completamente *naif* de los clasificadores, sin ningún esquema de validación. Esta tarea se deja al estudiante para repasar los contenidos de la primera sesión de prácticas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy as sp\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer, load_iris\n",
        "from sklearn.datasets import make_moons, make_circles, make_classification\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "breastCancer = datasets.load_breast_cancer()\n",
        "X_b = breastCancer.data\n",
        "y_b = breastCancer.target\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X_i = iris.data\n",
        "y_i = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos de SVM\n",
        "\n",
        "## Distintos tipos de SVM\n",
        "\n",
        "Hay varios tipos:\n",
        "\n",
        "- **SVC** es una implementación basada en la famosa libSVM ([https://www.csie.ntu.edu.tw/~cjlin/libsvm/](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)) y, en particular, la versión con el factor C que permite errores a la hora de buscar el margen.\n",
        "\n",
        "- SVC: El modelo general.\n",
        "- LinearSVC: Implementa solo el lineal, más eficiente y algunas regularizaciones adicionales. Usa la implementación de liblinear: [https://www.csie.ntu.edu.tw/~cjlin/liblinear/](https://www.csie.ntu.edu.tw/~cjlin/liblinear/).\n",
        "- NuSVC: Como el SVC, pero utiliza parámetro nu (ratio de margen de error).\n",
        "\n",
        "El nombre SVC se refiere a clasificación, para regresión es SVR.\n",
        "\n",
        "# Funciones sintéticas\n",
        "\n",
        "## Con funciones sintéticas \n",
        "\n",
        "Primero vamos a definir distintos datasets sintéticos, y un modelo por kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Hacemos un problema fácil de clasificar y que sea linealmente separable\n",
        "X, y = make_classification(\n",
        "    n_features=2, n_redundant=0, n_informative=2, random_state=0, n_clusters_per_class=1\n",
        ")\n",
        "rng = np.random.RandomState(2)\n",
        "X += 2 * rng.uniform(size=X.shape)\n",
        "linearly_separable = (X, y)\n",
        "\n",
        "datasets = [\n",
        "    make_moons(noise=0.3, random_state=0),\n",
        "    make_circles(noise=0.2, factor=0.5, random_state=0),\n",
        "    linearly_separable\n",
        "]\n",
        "\n",
        "models = {'linear': SVC(kernel='linear', C=1.0, random_state=0),\n",
        "          'poly': SVC(kernel='poly', degree=3, C=1.0, gamma=1,random_state=0),\n",
        "          'rbf': SVC(kernel='rbf', C=1.0, gamma=1,random_state=0)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Ahora vamos a pintar para cada dataset la gráfica. Primero el código.\n",
        "\n",
        "Hago uso de yellowbrick para pintar las regiones de decisión, usando una subfigura por conjunto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from yellowbrick.contrib.classifier import DecisionViz\n",
        "\n",
        "\n",
        "def pinta_regiones_decision_dataset(datasets, model):\n",
        "    fig, axs = plt.subplots(1, len(datasets), figsize=(12,6))\n",
        "    for (i, dataset) in enumerate(datasets):\n",
        "        viz = DecisionViz(model, ax=axs[i])\n",
        "        X, y = dataset\n",
        "        X = StandardScaler().fit_transform(X)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.4, random_state=42\n",
        "        )\n",
        "        viz.fit(X_train, y_train)\n",
        "        viz.draw(X_test, y_test)\n",
        "        viz.finalize()\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Probamos un enfoque lineal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pinta_regiones_decision_dataset(datasets, models['linear'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "Ahora un enfoque kernel _polinomial_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pinta_regiones_decision_dataset(datasets, models['poly'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "Ahora un enfoque kernel _rbf_:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pinta_regiones_decision_dataset(datasets, models['rbf'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "--- \n",
        "\n",
        "Ahora vamos a mostrar el comportamiento de cada uno de los modelos anteriores, usando cross_validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_validate, cross_val_score\n",
        "\n",
        "\n",
        "def pinta_regiones_decision_model(dataset, models):\n",
        "    fig, axs = plt.subplots(1, len(models), figsize=(12,6))\n",
        "    for (i, model) in enumerate(models):\n",
        "        viz = DecisionViz(model, ax=axs[i])\n",
        "        X, y = dataset\n",
        "        X = StandardScaler().fit_transform(X)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.4, random_state=42\n",
        "        )\n",
        "        viz.fit(X_train, y_train)\n",
        "        viz.draw(X_test, y_test)\n",
        "        viz.finalize()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def muestra_error_region(dataset, models):\n",
        "    for (name, model) in models.items():\n",
        "        X_d, y_d = dataset\n",
        "        scores = cross_validate(model, X_d, y_d, cv=5, scoring=('accuracy', 'roc_auc'))\n",
        "        accu = np.mean(scores['test_accuracy'])\n",
        "        print(f\"{name}: {accu:.2f}\", end=\"\\t\")\n",
        "\n",
        "    return pinta_regiones_decision_model(dataset, models.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Primer dataset: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "muestra_error_region(datasets[0], models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Segundo dataset: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "muestra_error_region(datasets[1], models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Tercer dataset: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "muestra_error_region(datasets[2], models)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# datasets\n",
        "\n",
        "## Sobre los datasets\n",
        "\n",
        "Vamos a ajustar sobre los conjuntos de entrenamiento de juguete de sklearn. Empezamos con Iris, que tiene atributos numéricos y, por tanto, no necesita hacer modificaciones en los atributos de entrada.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos a empezar con kernel lineal sencillo\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
        "\n",
        "svm.fit(X_i, y_i)\n",
        "y_pred = svm.predict(X_i)\n",
        "print(\"Informe completo\\n\",classification_report(y_i, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Si queremos ajustar sobre el conjunto de *breast_cancer*, nos encontramos con el problema de tener atributos nominales.\n",
        "\n",
        "Por defecto, se convertirán los atributos nominales a índices enteros, que sirven para el producto escalar, pero introducen un significado de magnitud relativa entre los valores nominales no existe en la realidad, pudiendo producir importantes problemas de rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
        "\n",
        "svm.fit(X_b, y_b)\n",
        "y_pred = svm.predict(X_b)\n",
        "print(\"Informe completo\\n\",classification_report(y_b, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Para solventar este problema, podemos utilizar *OneHotEncoding*, que transforma los atributos nominales en conjuntos de atributos binarios que sí que mantienen el sentido original de los valores categóricos al hacer el producto escalar en el Kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore') # Los valores perdidos se eliminarán\n",
        "\n",
        "X_b_onehot = one_hot.fit_transform(X_b) # ajustamos la transformación para crear los atributos (recuerda la regresión polinómica donde se introducían nuevos atributos!)\n",
        "\n",
        "#Vamos a comparar los atributos de entrada de los dos problemas\n",
        "print(X_b.shape)\n",
        "print(X_b_onehot.shape)\n",
        "\n",
        "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
        "\n",
        "svm.fit(X_b_onehot, y_b)\n",
        "y_pred = svm.predict(X_b_onehot)\n",
        "print(\"Informe completo\\n\",classification_report(y_b, y_pred)) #Compara los resultados con el anterior en el que no usábamos one-hot encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos a empezar con kernel lineal sencillo\n",
        "# nu es el parámetro de regularización, si lo ponemos muy alto, el modelo se ajustará mucho a los datos de entrenamiento\n",
        "# o directamente dará error porque no puede conseguir ajustarse a ese valor\n",
        "nusvm = NuSVC(kernel='linear', nu=0.5, random_state=0) \n",
        "\n",
        "nusvm.fit(X_i, y_i)\n",
        "y_pred = nusvm.predict(X_i)\n",
        "print(\"Informe completo NuSVM\\n\",classification_report(y_i, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problemas con múltiples clases\n",
        "\n",
        "## Estrategias de división del conjunto de entrenamiento para clasificadores binarios\n",
        "\n",
        "**!Un momento!** Iris es un conjunto con 3 clases. ¿Cómo está consiguiendo la SVM clasificar más de 2 etiquetas?\n",
        "Por defecto, SVC de Sklearn implementa *One versus Rest (OVR)* ó *One versus All (OVA)* como estrategia de división: se generarán subconjuntos a partir del conjunto de entrenamiento original, enfrentando cada clase frente a las otras combinadas.\n",
        "\n",
        "---\n",
        "\n",
        "Esta estrategia se diferencia *One versus All (OVO)*, que enfrenta cada clase frente a una del resto.\n",
        "\n",
        "![OVO y OVA](ovo_ovr.png){width=\"70%\"}\n",
        "\n",
        "Vamos a utilizar el *wrapper* de Sklearn para generar el mismo efecto en SVC para simular el efecto de OVO y  comprobar que los efectos son similares.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "\n",
        "svm_lineal = LinearSVC(C=1.0, random_state=0);\n",
        "\n",
        "svm_lineal.fit(X_i, y_i)\n",
        "y_pred = svm_lineal.predict(X_i)\n",
        "print(\"Informe completo para OVR incorporado\\n\",classification_report(y_i, y_pred))\n",
        "\n",
        "ovr = OneVsRestClassifier(LinearSVC(C=1.0,random_state=0)); # Usamos mismos parámetros que antes y la misma semilla\n",
        "ovr.fit(X_i, y_i)\n",
        "y_pred = ovr.predict(X_i)\n",
        "print(\"Informe completo para OVR wrapper\\n\",classification_report(y_i, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Ahora vamos a probar a utilizar el wrapper para utilizar **OVO** y observamos las diferencias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "#Para comparar fácilmente, recuperamos el último informe previo\n",
        "print(\"Informe completo para OVR wrapper\\n\",classification_report(y_i, y_pred))\n",
        "\n",
        "ovo = OneVsOneClassifier(LinearSVC(C=1.0,random_state=0)); # Usamos mismos parámetros que antes y la misma semilla\n",
        "ovo.fit(X_i, y_i)\n",
        "y_pred = ovo.predict(X_i)\n",
        "print(\"Informe completo para OVO wrapper\\n\",classification_report(y_i, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Por norma general, si el número de clases **no** es muy alto, la estrategia OVO es preferible. Genera problemas menos desequilibrados y más pequeños, que son más fáciles de tratar por el clasificador (y genera modelos más sencillos). Además, OVO es preferible en problemas desequilibrados originariamente, ya que no acentuará el desequilibrio como si acabará haciendo OVA.\n",
        "\n",
        "No obstante, la combinatoria juega en nuestra contra con OVO, por lo que ante un número de clases alto la estrategia OVA (o One vs. Rest) puede ser necesaria.\n",
        "\n",
        "## Ejercicios\n",
        "\n",
        "1. Probar para los problemas sintéticos cambios en los parámetros de los modelos para aplicar. Ver los cambios tanto en la gráfica como en las métricas.\n",
        "\n",
        "2. Probar con otro modelo de IA el uso de OVO y OVR."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}