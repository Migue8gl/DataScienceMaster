{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Optimización de parámetros\"\n",
        "theme: Montpellier\n",
        "author: \"Máster en Ciencias de Datos e Ingeniería de Computadores, Minería de Datos - Preprocesamiento y clasificación\"\n",
        "date: 11/11/2024\n",
        "date-format: long\n",
        "toc: true\n",
        "toc-title: Tabla de Contenidos\n",
        "toc-depth: 1\n",
        "execute:\n",
        "  echo: true\n",
        "output:\n",
        "  beamer_presentation:\n",
        "    slide_level: 1\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "    code-summary: \"Muestra código\"\n",
        "    fig-width: 5\n",
        "    fig-height: 3\n",
        "    fig-align: left\n",
        "  beamer:\n",
        "    fig-width: 4\n",
        "    fig-height: 2\n",
        "  revealjs:\n",
        "    theme: dark\n",
        "    fig-align: left\n",
        "    fig-height: 5\n",
        "    fig-cap-location: margin\n",
        "    smaller: true\n",
        "---\n",
        "\n",
        "# Introducción\n",
        "\n",
        "## Introducción\n",
        "\n",
        "El comportamiento de los algoritmos de ML dependen de muchos parámetros.\n",
        "\n",
        "- Los parámetros por defecto de Scikit-learn son muy buenos, no los mejores para un problema en concreto.\n",
        "\n",
        "- Importante: Cuidado con el sobre-aprendizaje, validar siempre.\n",
        "\n",
        "- Hacerlo _a mano_ es muy laborioso, pero Sklearn permite métodos para ajustar los parámetros a los métodos.\n",
        "\n",
        "- Los modelos de _tuning_ _envuelven_ al clasificador, y modifican el método fit().\n",
        "\n",
        "- Aún así es importante ajustar los más relevantes, no muchos.\n",
        "\n",
        "- Scikit-learn siempre aplica los métodos con validación cruzada para evitar sobre-aprendizaje.\n",
        "\n",
        "::: {.notes}\n",
        "Sklearn proporciona métodos para buscar los parámetros óptimos de los métodos, ajustándolos **al conjunto de entrenamiento** actual. Para ello, aplica una validación cruzada interna al propio conjunto de entrenamiento que podrá ser el conjunto completo o, a su vez, la partición de entrenamiento de otro esquema de validación. Esta validación cruzada interna y temporal es utilizada para comprobar el efecto de los parámetros en el clasificador, de forma **exhaustiva**.\n",
        ":::\n",
        "\n",
        "# Técnica de Rejilla: Grid Search\n",
        "\n",
        "## Técnica de Rejilla: Grid Search\n",
        "\n",
        "Es la técnica exhaustiva.\n",
        "\n",
        "Es fácil, para cada parámetro a optimizar se indica los valores.\n",
        "\n",
        "- Cuidado, puede llevar mucho tiempo, calcular lo que tardará."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "breastCancer = datasets.load_breast_cancer()\n",
        "X_b = breastCancer.data\n",
        "y_b = breastCancer.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejemplo de GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# No necesitamos especificar los parámetros\n",
        "svc = SVC() \n",
        "\n",
        "# Estudiamos dos valores de kernel, y números 1 y 10 para C\n",
        "parametros = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "\n",
        "# Aplica por defecto cv=5, lo pongo para mostrarlo\n",
        "ajuste = GridSearchCV(svc, parametros, cv=5, verbose=3)\n",
        "\n",
        "#La búsqueda de parámetros se hace con el método fit, como si fuera un clasificador\n",
        "ajuste.fit(X_b, y_b)\n",
        "\n",
        "#vamos a consultar los mejores parámetros encontrados\n",
        "print(ajuste.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## El modelo _mantiene_ los mejores parámetros\n",
        "\n",
        "**NO** es necesario apuntar en una hoja de papel los mejores parámetros. El objeto que produce GridSearchCV ya permite aplicar el método predict() con los mejores parámetros encontrados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_pred = ajuste.predict(X_b)\n",
        "print(\"Informe completo con búsqueda exhaustiva de parámetros\\n\",classification_report(y_b, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Búsqueda aleatoria de Parámetros\n",
        "\n",
        "## Búsqueda aleatoria de Parámetros\n",
        "\n",
        "Aunque **GridSearchCV** ofrece muy buenos resultados, cada valor de cada nuevo parámetro multiplica el número de combinaciones, por lo que puede ser muy lento.\n",
        "\n",
        "Otra opción es utilizar una búsqueda aleatorizada, muestreando cada posible combinación de una distribución de probabilidad (que puede ser elegida por el usuario) que se especifica para cada parámetro a optimizar.\n",
        "\n",
        "Esta búsqueda tiene la ventaja de que no aumenta el tiempo de búsqueda si los parámetros extra que se quieren buscar no aportan mejor rendimiento.\n",
        "\n",
        "## Ejemplo de Búsqueda Aleatoria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import scipy as sp\n",
        "\n",
        "# No necesitamos especificar los parámetros\n",
        "svc = SVC()\n",
        "\n",
        "# para 'C' y 'gamma' probamos valores usando una distribución exponencial\n",
        "parametros = {'C': sp.stats.expon(scale=100), 'gamma': sp.stats.expon(scale=.1),\n",
        "  'kernel': ['rbf']}\n",
        "\n",
        "# Genera por defecto solo 10 combinaciones, se modifica con n_iter\n",
        "ajuste = RandomizedSearchCV(svc, parametros, n_iter=10, verbose=3, random_state=12)\n",
        "\n",
        "ajuste.fit(X_b, y_b)\n",
        "\n",
        "print(ajuste.best_params_)\n",
        "\n",
        "y_pred = ajuste.predict(X_b)\n",
        "print(\"Informe completo con búsqueda aleatorizada de parámetros\\n\",classification_report(y_b, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Otro ejemplo de distribución de probabilidad para los parámetros C y gamma (del kernel RBF) con una loguniform.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Valores de C: \", sp.stats.loguniform(1e0, 1e3))\n",
        "parametros = {'C': sp.stats.loguniform(1e0, 1e3),\n",
        " 'gamma': sp.stats.loguniform(1e-4, 1e-3),\n",
        " 'kernel': ['rbf']}\n",
        "\n",
        "ajuste = RandomizedSearchCV(svc, parametros)\n",
        "\n",
        "ajuste.fit(X_b, y_b)\n",
        "\n",
        "print(ajuste.best_params_)\n",
        "\n",
        "y_pred = ajuste.predict(X_b)\n",
        "print(\"Informe completo con búsqueda aleatorizada de parámetros\\n\",classification_report(y_b, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Búsqueda de parámetros con *Succesive Halving*\n",
        "\n",
        "## Búsqueda de parámetros con *Successive halving*\n",
        "\n",
        "La división sucesiva a la mitad (Successive Halving -SH-) es similar a un carrera entre combinaciones de parámetros candidatos. SH es un proceso de selección iterativo en el que todos los candidatos (las combinaciones de parámetros) se evalúan con una pequeña cantidad de recursos en la primera iteración. Sólo algunos de estos candidatos se seleccionan para la siguiente iteración, a la que se asignan más recursos.\n",
        "\n",
        "Está disponible tanto para la búsqueda exhaustiva como para la aleatorizada.\n",
        "\n",
        "## Ejemplo de uso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "from sklearn.experimental import enable_halving_search_cv\n",
        "from sklearn.model_selection import HalvingGridSearchCV\n",
        "from sklearn.model_selection import HalvingRandomSearchCV\n",
        "\n",
        "svc = SVC() \n",
        "parametros = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "\n",
        "ajuste = HalvingGridSearchCV(svc, parametros) #la forma de construir la versión SH del grid search es idéntica a éste\n",
        "\n",
        "ajuste.fit(X_b, y_b)\n",
        "\n",
        "print(ajuste.best_params_)\n",
        "\n",
        "y_pred = ajuste.predict(X_b)\n",
        "print(\"Informe completo con búsqueda exhaustiva de parámetros (SH)\\n\",classification_report(y_b, y_pred))\n",
        "\n",
        "parametros = {'C': sp.stats.expon(scale=100), 'gamma': sp.stats.expon(scale=.1),\n",
        "  'kernel': ['rbf']}\n",
        "\n",
        "ajuste = HalvingRandomSearchCV(svc, parametros)\n",
        "\n",
        "ajuste.fit(X_b, y_b)\n",
        "\n",
        "print(ajuste.best_params_)\n",
        "\n",
        "y_pred = ajuste.predict(X_b)\n",
        "print(\"Informe completo con búsqueda aleatorizada de parámetros (SH)\\n\",classification_report(y_b, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Otras alternativas\n",
        "\n",
        "## Otras alternativas\n",
        "\n",
        "Existen distintos programas para optimizar parámetros que se pueden usar de forma sencilla para Scikit-learn.\n",
        "\n",
        "- Hyperopt: [https://hyperopt.github.io/hyperopt/](https://hyperopt.github.io/hyperopt/).\n",
        "- Optuna: [https://optuna.readthedocs.io/en/stable/](https://optuna.readthedocs.io/en/stable/).\n",
        "\n",
        "Veremos solo Hyperopt porque tiene un interfaz más sencillo para Sklearn.\n",
        "\n",
        "## Hyperopt\n",
        "\n",
        "- Presenta un interfaz distinto de Sklearn, pero el paquete hpsklearn permite una clase que implementa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "!pip install hyperopt hpsklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Luego se usa la clase **HyperoptEstimator** que es similar a las clases anteriores.\n",
        "\n",
        "Debe de trabajar con sus propias clases de clasificadores, no directamente las de Scikit-learn.\n",
        "\n",
        "## Ejemplo de Hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "from hpsklearn import HyperoptEstimator, svc\n",
        "from hyperopt import hp\n",
        "\n",
        "# Usamos  choice, pero tiene para distribuciones normal, uniform, ....\n",
        "pkernel = hp.choice('kernel', ['linear', 'rbf'])\n",
        "pC = hp.choice('C', [1, 10])\n",
        "ajuste = HyperoptEstimator(classifier=svc(\"mySVC\"), max_evals=50)\n",
        "\n",
        "ajuste.fit(X_b, y_b)\n",
        "print(ajuste.best_model())\n",
        "y_pred = ajuste.predict(y_b)\n",
        "print(\"Informe completo con búsqueda de parámetros (Hyperopt)\\n\",classification_report(y_b, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}