{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Árboles de decisión\n",
        "jupyter: python3\n",
        "theme: Montpellier\n",
        "author:  Máster en Ciencias de Datos e Ingeniería de Computadores\n",
        "      Minería de Datos - Preprocesamiento y clasificación\n",
        "date: Octubre 2024\n",
        "toc-title: Tabla de Contenidos\n",
        "toc: true\n",
        "toc-depth: 1\n",
        "# classoption: compress\n",
        "execute:\n",
        "  echo: true\n",
        "output:\n",
        "  beamer_presentation:\n",
        "    slide_level: 1\n",
        "    includes:\n",
        "      in_header: ./simple.txt\n",
        "format:\n",
        "  html:\n",
        "    code-fold: false\n",
        "    code-summary: \"Muestra código\"\n",
        "    fig-width: 5\n",
        "    fig-height: 3\n",
        "    fig-align: left\n",
        "  beamer:\n",
        "    fig-width: 4\n",
        "    fig-height: 2\n",
        "  revealjs:\n",
        "    theme: dark\n",
        "    fig-align: left\n",
        "    fig-height: 3\n",
        "    fig-cap-location: margin\n",
        "    smaller: true\n",
        "---\n",
        "\n",
        "# Arboles de decisión\n",
        "\n",
        "En este notebook vamos a repasar los principales métodos de árboles de decisión vistos en teoría. \n",
        "\n",
        "Se aplica una evaluación completamente *naif* de los clasificadores, sin ningún esquema de validación. Esta tarea se deja al estudiante para repasar los contenidos de la primera sesión de prácticas.\n",
        "\n",
        "Vamos a usar el dataset del breastCancer, e Iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: true\n",
        "import sklearn\n",
        "import numpy as np # debe ser una versión previa a la 1.24 para ID3. En Anaconda, por ejemplo, usar conda install numpy=1.23\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "#from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer, load_iris, load_wine\n",
        "from sklearn.datasets import load_iris, load_diabetes\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "\n",
        "#from matplotlib import style\n",
        "#style.use('dark_background')\n",
        "\n",
        "breastCancer = datasets.load_breast_cancer()\n",
        "wine = datasets.load_wine()\n",
        "diabetes = datasets.load_diabetes()\n",
        "X_b = breastCancer.data\n",
        "y_b = breastCancer.target\n",
        "students = pd.read_csv(\"student-por.csv\", sep=';')\n",
        "X_s = students.drop(\"G3\",axis=1)\n",
        "y_s = students.G3\n",
        "\n",
        "# Encode the values\n",
        "# Se explicará en preprocesamiento\n",
        "encoders = {}\n",
        "for col in X_s.select_dtypes(include='object'):\n",
        "    encoders[col] = LabelEncoder().fit(X_s[col])\n",
        "    X_s[col] = encoders[col].transform(X_s[col])\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X_i = iris.data\n",
        "y_i = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ID3\n",
        "\n",
        "ID3 no está oficialmente en SKlearn, pero sí en el repositorio Pip. \n",
        "\n",
        "Hay varios paquetes:\n",
        "\n",
        "- [decision-tree-id3](https://pypi.org/project/decision-tree-id3/): Requiere numpy previa a la 1.24 para que funcione.\n",
        "- [ID3Classifier](https://pypi.org/project/ID3classifier/):  Actualizado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install ID3classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "El ID3 instalado tiene la misma interfaz de fit & predict de sklearn, por lo que podemos usarla en los pipelines de sklearn.\n",
        "Vamos a realizar un ejemplo de ajuste sencillo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from ID3classifier import ID3\n",
        "# Create an instance of the ID3 classifier\n",
        "id3 = ID3(max_depth=4, min_samples_split=2)\n",
        "id3.fit(X_s, y_s)\n",
        "\n",
        "y_pred = id3.predict(X_s)\n",
        "# id3.print_tree() No funciona, no sé por qué, pero no es importante\n",
        "print(\"Informe completo\\n\",classification_report(y_s, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usando entropy para comparar\n",
        "\n",
        "Vamos a utilizar el método DecisionTreeClassifier de sklearn con la medida **entropy** para realizar la partición de los datos y comparamos con el resultado del paquete ad-hoc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "id3_sk = tree.DecisionTreeClassifier(max_depth=4, min_samples_split=2, criterion='entropy')\n",
        "id3_sk.fit(X_s, y_s)\n",
        "\n",
        "y_pred = id3_sk.predict(X_s)\n",
        "print(\"Informe completo\\n\",classification_report(y_s, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizando el árbol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: True\n",
        "dot_data = tree.export_graphviz(id3_sk, out_file=None, feature_names=X_s.columns, impurity=False) \n",
        "\n",
        "# dot_data = tree.export_graphviz(id3_sk, out_file=None, \n",
        "#                      feature_names=X_s.columns,  \n",
        "#                      filled=True, rounded=True,  \n",
        "#                      special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"tree_students\")\n",
        "display(graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# C4.5\n",
        "\n",
        "El DecisionTree de Sklearn permite usar la medida de impureza de C4.5, pero no exactamente su criterio de selección de atributos, gestión de valores perdidos, etc.\n",
        "\n",
        "Vamos a utilizar una implementación no oficial más fiel al C4.5 original de Quinlan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from c45 import C45\n",
        "\n",
        "c_45 = C45(attrNames=X_s.columns)\n",
        "\n",
        "c_45.fit(X_s, y_s)\n",
        "\n",
        "y_pred = c_45.predict(X_s)\n",
        "print(\"Informe completo\\n\",classification_report(y_s, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CART\n",
        "\n",
        "En este caso, sklearn sí tiene una implementación de CART fiel y podemos usarla directamente sin software externo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cart = tree.DecisionTreeClassifier(criterion='gini')\n",
        "cart.fit(X_i, y_i)\n",
        "\n",
        "y_pred = cart.predict(X_i)\n",
        "\n",
        "print(\"Informe completo\\n\",classification_report(y_i, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Los métodos que generan los ficheros .dot pueden visuzalizarse usando graphviz (hay que instalarlo en conda/pip, también desde la web y las interfaces al lenguaje python).\n",
        "Vamos a dibujar el último árbol de decisión generado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| code-fold: True\n",
        "import graphviz \n",
        "\n",
        "# https://stackoverflow.com/questions/52566756/no-module-named-graphviz-in-jupyter-notebook si tienes problemas con graphviz\n",
        "\n",
        "dot_data = tree.export_graphviz(cart, out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph.render(\"iris\") #Buscar el fichero iris.pdf en la carpeta de trabajo\n",
        "display(graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Propuestos\n",
        "\n",
        "1. Aplica en iris y en students la separación vista en análisis para ver los estudios.\n",
        "2. Probarlo con max_depth de 5, 10, y sin especificar, y comparar la diferencia.\n",
        "3. Visualizar los árboles del ejercicio anterior."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/usr/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}