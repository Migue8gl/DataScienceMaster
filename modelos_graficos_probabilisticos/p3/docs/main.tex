\documentclass[12pt,letterpaper]{article}
\usepackage[a4paper, top=1.2in, bottom=1.4in, left=1in, right=1in]{geometry}
\usepackage{graphicx} % Required for inserting images
\graphicspath{ {./img/} }
\usepackage[spanish]{babel}
\usepackage{float}
\usepackage{fancyhdr}
\setlength{\parskip}{1em}  % Adds space between paragraphs (1em)
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{listings}
\usepackage[utf8]{inputenc}

\usepackage{xcolor}

\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{orange},
    showstringspaces=false,
    frame=single,
    breaklines=true
}
\usepackage{subcaption}
\newcommand{\tikzmark}[1]{\tikz[baseline,remember picture] \coordinate (#1) {};}
\usetikzlibrary{positioning}
\usetikzlibrary{shadows,arrows.meta} % For adding edges label
\usetikzlibrary{calc}
\usepackage{eso-pic}
\usepackage[backend=biber, defernumbers=true, citestyle=numeric-comp, bibstyle=ieee, sorting=none]{biblatex}
\addbibresource{bibliography/bibliography.bib}
\DeclareBibliographyCategory{cited}
\AtEveryCitekey{\addtocategory{cited}{\thefield{entrykey}}}
% Configurando BibLaTeX
\DefineBibliographyStrings{spanish}{
  url = {URL},
  andothers={et ~al\adddot}
}
\usepackage{listings}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\AddToShipoutPictureBG{%
\begin{tikzpicture}[remember picture, overlay]
\node[opacity=.15, inner sep=0pt]
    at(current page.center){\includegraphics[scale=1.5]{img/logo-ugr2.png}};
\end{tikzpicture}%
}

\title{MGP - P3}
\author{Miguel García López}
\date{Marzo 2025}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{Miguel García López}            
\chead{\textbf{\small MGP - P3}}
\rhead{Master Ciencia de Datos \\ \today}
\lfoot{\scriptsize\LaTeX}
\cfoot{\small MGP - P3}
\rfoot{\small\thepage}
\headsep 1.5em

\author{Miguel García López} % Nombre y apellidos

\date{\normalsize\today} % Incluye la fecha actual

\begin{document}
\begin{titlepage}
    \begin{figure}
        \vspace{-1.3cm}
        \begin{center}
            \includegraphics[width=0.75\textwidth]{img/UGR-Logo.png}
        \end{center}
    \end{figure}
    \vspace{1.3cm}
    \centering
    \normalfont \normalsize
    \textsc{\textbf{Modelos Gráficos Probabilísticos - 2024-2025} \\ \vspace{.15cm} Master Ciencia de Datos\\ \vspace{.15cm} Universidad de Granada} \\ [25pt]
    \huge Práctica 3

    \normalfont \normalsize \vspace{.30cm}
    \textsc{Miguel García López}

\end{titlepage}

\tableofcontents
\listoffigures
\listoftables
\newpage

\section{Introducción}
El objetivo de esta práctica es aplicar técnicas de aprendizaje de redes bayesianas utilizando el lenguaje de programación R, haciendo uso de diversos paquetes especializados como \texttt{bnlearn}, \texttt{gRain}, y \texttt{Rgraphviz}.

A lo largo de este trabajo se abordarán aspectos esenciales del aprendizaje de redes bayesianas, tales como la estimación de parámetros mediante distribuciones de probabilidad condicional, los tests de independencia, y el uso de distintos \textit{scores} para la evaluación de modelos. Asimismo, se explorará el proceso de aprendizaje de la estructura del grafo acíclico dirigido (DAG) que subyace a la red, a través de métodos basados en pruebas estadísticas y en medidas de evaluación.

\section{Red seleccionada}
La red \textbf{SACHS} (figura \ref{fig:sachs}) es una red bayesiana derivada de datos experimentales sobre proteínas y señales celulares. Fue presentada por K. Sachs et al. en su estudio sobre inferencia de redes causales en sistemas biológicos. Esta red es ampliamente utilizada como referencia en el aprendizaje de redes bayesianas, debido a su complejidad intermedia y su relevancia en biología de sistemas.

La red contiene un total de $11$ nodos, cada uno representando una proteína o una señal biológica, y $17$ arcos dirigidos que modelan las relaciones causales o dependencias condicionales entre estas variables. Además, cuenta con un total de $178$ parámetros necesarios para definir las distribuciones de probabilidad condicional asociadas a cada nodo. La estructura de la red presenta un \textit{grado medio} y un \textit{tamaño medio del manto de Markov} de aproximadamente $3.09$, reflejando una conectividad moderada entre los nodos. El grado máximo de entrada (número máximo de padres de un nodo) es $3$, indicando que ningún nodo depende directamente de más de tres variables.

\begin{table}[htp]
    \centering
    \caption{Resumen de los parámetros de la red SACHS}
    \vspace{0.3cm}
    \begin{tabular}{@{}ll@{}}
        \toprule
        \textbf{Característica}             & \textbf{Valor} \\ \midrule
        Nombre de la red                    & SACHS          \\
        Número de nodos                     & 11             \\
        Número de arcos (relaciones)        & 17             \\
        Número total de parámetros          & 178            \\
        Tamaño medio del manto de Markov    & 3.09           \\
        Grado medio                         & 3.09           \\
        Máximo grado de entrada (in-degree) & 3              \\
        \bottomrule
    \end{tabular}
    \label{tabla:sachs_parametros}
\end{table}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.8\linewidth]{./img/sachs.png}
    \caption{DAG de la red SACHS}
    \label{fig:sachs}
\end{figure}

Los archivos de la red están disponibles en varios formatos compatibles con herramientas de aprendizaje y análisis de redes bayesianas, tales como BIF, DSC, NET y RDA/RDS para objetos \texttt{bn.fit} en R.

\section{Estructuras obtenidas}
En esta sección, se realizan simulaciones de datos, el aprendizaje de la estructura mediante distintos algoritmos y la comparación de los modelos obtenidos respecto a la red original.

Para evaluar el comportamiento de los algoritmos de aprendizaje de estructuras de redes bayesianas, se simulan dos conjuntos de datos de distinto tamaño a partir de la red original SACHS:
\begin{itemize}
    \item Un primer conjunto de datos con $200$ observaciones.
    \item Un segundo conjunto de datos con $5000$ observaciones.
\end{itemize}

La simulación se realiza mediante la función \texttt{rbn()}, que permite generar datos sintéticos a partir de una red bayesiana previamente definida.

\begin{lstlisting}
# Simular conjunto de datos con 200 casos
data_200 <- rbn(sachs, n = 200)
# Simular conjunto de datos con 5000 casos
data_5000 <- rbn(sachs, n = 5000)

# Mostrar las primeras filas de cada conjunto de datos
head(data_200)
head(data_5000)
\end{lstlisting}


Se procede a aprender la estructura de la red a partir de los datos simulados, empleando dos métodos distintos:
\begin{enumerate}
    \item \textbf{Método basado en scores}: utiliza algoritmos de búsqueda, como Hill-Climbing (\texttt{hc}), evaluando las estructuras mediante una función de puntuación.
    \item \textbf{Método basado en tests de independencia}: utiliza algoritmos como \texttt{iamb}, que se basan en pruebas de independencia condicional para determinar la estructura.
\end{enumerate}

Los algoritmos se aplican a ambos conjuntos de datos (200 y 5000 observaciones) para evaluar cómo afecta el tamaño de la muestra al resultado.

\begin{lstlisting}
# Metodo basado en scores (Hill-Climbing)
learned_score_200 <- hc(data_200)
modelstring(learned_score_200)
graphviz.plot(learned_score_200)

learned_score_5000 <- hc(data_5000)
modelstring(learned_score_5000)
graphviz.plot(learned_score_5000)

# Metodo basado en tests de independencia (IAMB)
learned_independence_200 <- iamb(data_200)
learned_independence_200 <- cextend(learned_independence_200)
modelstring(learned_independence_200)
graphviz.plot(learned_independence_200)

learned_independence_5000 <- iamb(data_5000)
learned_independence_5000 <- cextend(learned_independence_5000)
modelstring(learned_independence_5000)
graphviz.plot(learned_independence_5000)
\end{lstlisting}

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.8\linewidth]{./img/learned_score200.png}
    \caption{DAG aprendido con método de \textit{score} con $200$ ejemplos.}
    \label{fig:learnedscore200}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.8\linewidth]{./img/learned_score5000.png}
    \caption{DAG aprendido con método de \textit{score} con $5000$ ejemplos.}
    \label{fig:learnedscore5000}
\end{figure}

Se procede a comparar primero las redes obtenidas por medio de un algoritmo de \textit{score}. En las figuras \ref{fig:learnedscore200} y \ref{fig:learnedscore5000} se pueden observar las dos redes obtenidas tras realizar el ajuste con los datos simulados.

Lo primero que salta a la vista es la división de dos grafos principales, el grafo parece estar dividido por dos sub-grafos desconectados entre si. Esto se ha visto reflejado en ambos DAGs obtenidos. Si bien el grafo más pequeño no refleja la relación completa entre las variables $PIP2, PIP3$ y $Plcg$, ha podido representar la separación con el resto de variables. En el grafo más grande se obtiene un DAG inverso al original, pues las aristas están conectadas correctamente, pero orientadas en sentido contrario.

Esto es debido a que muchos DAGs equivalentes a nivel de independencia condicional pueden diferir solo en la orientación de sus aristas.
Si dos grafos representan las mismas independencias condicionales, los algoritmos de estructura no siempre pueden decidir la dirección correcta solo con datos (sin intervención o conocimiento a priori).

Ocurre lo mismo en el sub-grafo grande de ambos DAGs (sobre todo el DAG de $5000$ ejemplos, pues capta mejor la complejidad del original). Se relacionan variables como $PKC$ con las correctas, pero con las aristas mal orientadas en el sentido de la dirección. En general se captura bien relaciones entre variables, aunque hay algún fallo, como la relación entre $Mek$ y $Akt$ del grafo en la figura \ref{fig:learnedscore5000}. En el original esta relación no es inmediata, sino que existe un nodo intermedio que es $Erk$. Esto significa que el algoritmo ha captado una dependencia estadística real (porque $Mek$ y $Akt$ están relacionados), pero no ha sido capaz de reflejar que esa relación está mediada por $Erk$.

\begin{figure}[htp]
    \centering
    \includegraphics[width=0.8\linewidth]{./img/learned_ind200.png}
    \caption{DAG aprendido con método de \textit{tests} de independencia con $200$ ejemplos.}
    \label{fig:learnedindp200}
\end{figure}
\begin{figure}[htp]
    \centering
    \includegraphics[width=0.8\linewidth]{./img/learned_ind5000.png}
    \caption{DAG aprendido con método de \textit{tests} de independencia con $5000$ ejemplos.}
    \label{fig:learnedindp5000}
\end{figure}

En el caso de los grafos aprendidos por medio de un algoritmo que hace uso de \textit{tests} de independencia (figuras \ref{fig:learnedindp200}, \ref{fig:learnedindp5000}) puede verse a primera vista que el ajuste en relación con el original es peor.
El grafo pequeño no ha sido capaz de captar demasiadas relaciones entre variables, aunque las pocas que ha encontrado están bien orientadas y son correctas. En el grafo grande siguen existiendo problemas de direccionalidad, pero el sub-grafo de tres variables ($PIP2, PIP3, Plcg$) ha sido representado de manera perfecta.

En esta red concreta y dados los pocos experimentos realizados, lo que se puede observar a simple vista es que los grafos obtenidos por medio de algoritmos basados en \textit{score} son mejores aprendiendo la estructura general del DAG. Si bien ambos fallan en la orientación de las relaciones condicionales, el que considero que capta mejor esas relaciones es el \texttt{hc}.

\section{Parámetros aprendidos}
Se procede a aprender los parámetros de las redes por medio del conjunto de datos respectivo a cada red
\begin{lstlisting}
    fit_hc_200 <- bn.fit(learned_score_200, data_200)
    fit_hc_5000 <- bn.fit(learned_score_5000, data_5000)
    fit_iamb_200 <- bn.fit(learned_independence_200, data_200)
    fit_iamb_5000 <- bn.fit(learned_independence_5000, data_5000)
\end{lstlisting}

\begin{table}[htp]
    \centering
    \begin{tabular}{l|c|c|c}
        \hline
        \textbf{Modelo}   & \textbf{LOW} & \textbf{AVG} & \textbf{HIGH} \\ \hline
        \textbf{Original} & 0.85         & 0.39         & 0.01          \\ \hline
        HC (n=200)        & 0.14         & 0.83         & 0.02          \\ \hline
        HC (n=5000)       & 0.14         & 0.81         & 0.05          \\ \hline
        IAMB (n=200)      & 0.75         & 0.25         & 0.00          \\ \hline
        IAMB (n=5000)     & 0.94         & 0.06         & 0.00          \\ \hline
    \end{tabular}
    \caption{Parámetros de \texttt{Erk} (Mek = LOW, PKA = LOW).}
    \label{tab:erk_low_low}
\end{table}

\begin{table}[htp]
    \centering
    \begin{tabular}{l|c|c|c}
        \hline
        \textbf{Modelo}   & \textbf{LOW} & \textbf{AVG} & \textbf{HIGH} \\ \hline
        \textbf{Original} & 0.05         & 0.73         & 0.22          \\ \hline
        HC (n=5000)       & 0.16         & 0.84         & 0.00          \\ \hline
        IAMB (n=5000)     & 0.05         & 0.39         & 0.55          \\ \hline
    \end{tabular}
    \caption{Parámetros de \texttt{Erk} (Mek = AVG, PKA = AVG).}
    \label{tab:erk_avg_avg}
\end{table}

\begin{table}[htp]
    \centering
    \begin{tabular}{l|c|c|c}
        \hline
        \textbf{Modelo}   & \textbf{LOW} & \textbf{AVG} & \textbf{HIGH} \\ \hline
        \textbf{Original} & 0.06         & 0.92         & 0.02          \\ \hline
        HC (n=200)        & 0.05         & 0.95         & 0.00          \\ \hline
        HC (n=5000)       & 0.37         & 0.63         & 0.00          \\ \hline
    \end{tabular}
    \caption{Parámetros de \texttt{PKA} (PKC = AVG).}
    \label{tab:pka_avg}
\end{table}


En la tabla~\ref{tab:erk_low_low}, se observa que el modelo original asigna una alta probabilidad a \texttt{Erk = LOW} (0.85). Sin embargo, HC con \( n = 200 \) y con \( n = 5000 \) estima una probabilidad menor (0.14), indicando pobre ajuste de las probabilidades. Con IAMB, ambos métodos mejoran, acercándose al original. En la Tabla~\ref{tab:erk_avg_avg}, HC con \( n = 5000 \) recupera mejor la estructura, asignando 0.84 a \texttt{AVG}, mientras que IAMB subestima esta probabilidad (0.39).

\end{document}
